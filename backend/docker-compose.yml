version: '3.8'

services:
  pdf-reader-backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: pdf-reader-backend
    ports:
      - "5002:5002"
    environment:
      - FLASK_ENV=development
      - PORT=5002
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - GEMINI_API_KEY=${GEMINI_API_KEY:-}
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      - LLM_MODEL=${LLM_MODEL:-gpt-4o}
      - LLM_TEMPERATURE=${LLM_TEMPERATURE:-0.1}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS:-1000}
      - EMBEDDING_PROVIDER=${EMBEDDING_PROVIDER:-sentence-transformers}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-all-mpnet-base-v2}
    volumes:
      - ./uploads:/tmp/uploads
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Optional: Add a reverse proxy for production
  nginx:
    image: nginx:alpine
    container_name: pdf-reader-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - pdf-reader-backend
    restart: unless-stopped
    profiles:
      - production

volumes:
  uploads:
    driver: local
